{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JORViGQAugmh"
      },
      "source": [
        "\n",
        "## Esempi Pratici\n",
        "\n",
        "### 1. Estrazione di Carte\n",
        "Consideriamo l'estrazione di due carte da un mazzo standard di 52 carte senza reinserimento.\n",
        "\n",
        "Qual è la probabilità di estrarre due assi?\n",
        "\n",
        "1. Prima estrazione ($\\mathcal{A}_1$): $P(\\mathcal{A}_1) = \\frac{4}{52} = \\frac{1}{13}$\n",
        "2. Seconda estrazione ($\\mathcal{A}_2$), dato che abbiamo già estratto un asso:\n",
        "   $P(\\mathcal{A}_2|\\mathcal{A}_1) = \\frac{3}{51} = \\frac{1}{17}$\n",
        "\n",
        "La probabilità di estrarre due assi è quindi:\n",
        "\n",
        "$$P(\\mathcal{A}_1 \\cap \\mathcal{A}_2) = \\frac{1}{13} \\cdot \\frac{1}{17} = \\frac{1}{221}$$\n",
        "\n",
        "Si noti che questi eventi non sono indipendenti!\n",
        "\n",
        "### 2. Lancio di Dadi\n",
        "Lanciamo due dadi. Qual è la probabilità di ottenere un 6 sul primo dado e un numero pari sul secondo?\n",
        "\n",
        "1. Primo evento ($\\mathcal{D}_6$): ottenere 6 sul primo dado\n",
        "   $P(\\mathcal{D}_6) = \\frac{1}{6}$\n",
        "2. Secondo evento ($\\mathcal{P}$): ottenere un numero pari sul secondo dado\n",
        "   $P(\\mathcal{P}|\\mathcal{D}_6) = \\frac{3}{6} = \\frac{1}{2}$ (i due eventi sono indipendenti)\n",
        "\n",
        "$$P(\\mathcal{D}_6 \\cap \\mathcal{P}) = \\frac{1}{6} \\cdot \\frac{1}{2} = \\frac{1}{12}$$\n",
        "\n",
        "### 3. Esempio con Tre Eventi\n",
        "Consideriamo un processo di controllo qualità con tre fasi:\n",
        "\n",
        "1. $\\mathcal{M}$: il materiale passa il controllo iniziale\n",
        "2. $\\mathcal{D}$: il design è approvato\n",
        "3. $\\mathcal{T}$: il test finale è superato\n",
        "\n",
        "Supponiamo:\n",
        "- $P(\\mathcal{M}) = 0.9$ (90% dei materiali passa il controllo)\n",
        "- $P(\\mathcal{D}|\\mathcal{M}) = 0.8$ (80% dei design con materiali approvati passa)\n",
        "- $P(\\mathcal{T}|\\mathcal{M} \\cap \\mathcal{D}) = 0.95$ (95% dei prodotti con materiali e design approvati passa il test finale)\n",
        "\n",
        "La probabilità che un prodotto superi tutte e tre le fasi è:\n",
        "\n",
        "$$P(\\mathcal{M} \\cap \\mathcal{D} \\cap \\mathcal{T}) = 0.9 \\cdot 0.8 \\cdot 0.95 = 0.684$$\n",
        "\n",
        "\n",
        "## Applicazioni\n",
        "\n",
        "La regola del prodotto è fondamentale in molti campi:\n",
        "\n",
        "1. **Analisi dei Rischi**: Calcolare la probabilità di una serie di eventi che devono verificarsi tutti per un fallimento del sistema\n",
        "2. **Machine Learning**: Nella costruzione di modelli probabilistici, come le catene di Markov, tanto usate per il decision making sequenziale e la massimizzazione di profitto a lungo periodo.\n",
        "3. **Genetica**: Calcolare la probabilità di ereditare specifiche combinazioni di geni.\n",
        "\n",
        "## Visualizzazione con Alberi delle Probabilità\n",
        "\n",
        "Gli alberi delle probabilità sono strumenti utili per visualizzare e calcolare probabilità usando la regola del prodotto:\n",
        "\n",
        "- nei nodi andiamo a collocare gli eventi. Iniziando col mettere al nodo radice, l'evento certo, cioè $\\Omega$.\n",
        "- Ogni nodo genera dei nodi figli, che definiscono una partizione sul nodo precedente, cioè una serie di tutti i casi possibili e mutuamente esclusivi che si possono dare dopo che si è dato l'evento padre. Nel più comune dei casi, ogni nodo $\\mathcal{A}$ genera due figli, quello relazionato con un possibile evento successivo $\\mathcal{B}$ e il suo complementare $\\bar{\\mathcal{B}}$. (Si noti che, per qualiasi evento $\\mathcal{B}$, si ha che  $\\{\\mathcal{B},\\bar{\\mathcal{B}}\\}$ è una partizione). Ai nodi ci possono essere eventi singoli come $\\mathcal{A}$ oppure eventi congiunti come $\\mathcal{A} \\cap \\mathcal{B}$.\n",
        "- Nei rami andiamo a scrivere le probabilità condizionate a seconda dell'evento congiunto che il ramo genera. Vediamo un esempio:\n",
        "\n",
        "```\n",
        "                            P(A∩B) = 0.28\n",
        "                            /\n",
        "                           /\n",
        "                      P(B|A) = 0.7\n",
        "                         /                     \n",
        "              P(A) = 0.4                      \n",
        "            /           \\                     \n",
        "           /          P(B'|A) = 0.3\n",
        "P(Ω)=1.0 ---              \\\n",
        "           \\               \\\n",
        "            \\               P(A∩B') = 0.12\n",
        "             \\            \n",
        "              \\           \n",
        "               \\            P(A'∩B) = 0.18\n",
        "                \\          /\n",
        "                 \\        /\n",
        "                  \\    P(B|A') = 0.3\n",
        "                   \\    /\n",
        "              P(A') = 0.6\n",
        "                        \\\n",
        "                        P(B'|A') = 0.7\n",
        "                          \\           \n",
        "                           \\              \n",
        "                            P(A'∩B') = 0.42        \n",
        "```\n",
        "\n",
        "- Questo tipo di visualizzazione aiuta a capire come, per arrivare a calcolare le probabilità degli eventi sui nodi, possiamo semplicemente moltiplicare le probabilità si moltiplicano lungo i rami dell'albero.\n",
        "\n",
        "- Se non resta chiaro perché abbiamo usato $P(\\mathcal{A})$, che non è sui rami dell'albero, allora potremmo disegnare diversamente l'albero:\n",
        "\n",
        "\n",
        "```\n",
        "                            P(A∩B) = 0.28\n",
        "                           /\n",
        "                          /\n",
        "                    P(B|A) = 0.7\n",
        "                        /                     \n",
        "                       A\n",
        "                     /  \\\n",
        "                    /   P(B'|A) = 0.3\n",
        "          P(A|Ω) = 0.4    \\                 \n",
        "                 /         \\                     \n",
        "                /          P(A∩B') = 0.12\n",
        "P(Ω)=1.0 -------            \n",
        "                \\                   \n",
        "                 \\            \n",
        "              P(A'|Ω) = 0.6           \n",
        "                   \\          P(A'∩B) = 0.18\n",
        "                    \\        /\n",
        "                     \\      /\n",
        "                      \\  P(B|A') = 0.3\n",
        "                       \\  /\n",
        "                        A'\n",
        "                          \\\n",
        "                        P(B'|A') = 0.7\n",
        "                             \\           \n",
        "                              \\              \n",
        "                             P(A'∩B') = 0.42        \n",
        "```\n",
        "E ora dovrebbe essere più chiaro come, per arrivare alle probabilità degli eventi sui nodi, si moltiplicano le probabilità sui rami."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgwCLMOryJFB"
      },
      "source": [
        "Nei seguenti diagrammi, per comodità, le probabilità congiunte del tipo $P(\\mathcal{A}\\cap \\mathcal{B})$, vengono espresse così: $ P(\\mathcal{A} , \\mathcal{B})$, oppure direttamente così $ \\mathcal{A} , \\mathcal{B}$:\n",
        "\n",
        "\n",
        "### Esempio 1: Test Medico\n",
        "\n",
        "Consideriamo un test medico per una malattia rara:\n",
        "- Prevalenza della malattia: 1%\n",
        "- Sensibilità del test: 95% (P(Positivo|Malattia))\n",
        "- Specificità del test: 90% (P(Negativo|No Malattia))\n",
        "\n",
        "```                \n",
        "                         P(M∩+) = 0.0095\n",
        "                        /\n",
        "                       /\n",
        "                      P(+|M) = 0.95\n",
        "                     /\n",
        "            P(M) = 0.01\n",
        "           /         \\\n",
        "          /           P(-|M) = 0.05\n",
        "P(Ω) = 1.0             \\\n",
        "         \\              P(M∩-) = 0.0005\n",
        "          \\\n",
        "           \\                P(NM∩+) = 0.099\n",
        "            \\             /\n",
        "             \\         P(+|NM) = 0.10\n",
        "              \\         /\n",
        "              P(NM) = 0.99\n",
        "                        \\\n",
        "                        P(-|NM) = 0.90\n",
        "                          \\\n",
        "                           P(NM∩-) = 0.891\n",
        "```\n",
        "\n",
        "Calcoli utili:\n",
        "- P(Test Positivo) = 0.0095 + 0.099 = 0.1085\n",
        "- P(Malattia|Test Positivo) = 0.0095 / 0.1085 ≈ 0.088  (Vedremo tra poco come abbiamo calcolato questo caso, ma per esercizio, potresti cercare di arrivarci giocando con la definizione e le proprietà di probabilità congiunta e condizionata ;)\n",
        "\n",
        "\n",
        "\n",
        "## Esempio 2: Tre Lanci di Moneta\n",
        "\n",
        "Probabilità di ottenere testa $P(T) = 0.5$, prob. di ottenere croce $P(C) = 0.5$. Notiamo che l'esito dei lanci successivi non viene influenzato da quello dei lanci precedenti, sono eventi indipendenti infatti.\n",
        "\n",
        "Si noti anche come è naturale scrivere o leggere le ramificazione dell'albero seguendo la sucessione temporale dei lanci di moneta.\n",
        "\n",
        "In questo e nei prossimi diagrammi ommettiamo le probabilità condizionate sui rami, per semplicità di disegno. Ad ogni modo si noti che le probabilità condizionate qui sono uguali a quelle \"marginali\" per l'ipotesi di indipendenza tra eventi:\n",
        "\n",
        "$P(T|C)= P(T)$ e $P(T|T \\cap C)=P(T)$, ecc...\n",
        "\n",
        "\n",
        "```\n",
        "                                            P(T∩T∩T) = 0.125\n",
        "                                           /\n",
        "                                          /\n",
        "                            P(T∩T) = 0.25\n",
        "                           /              \\\n",
        "                          /                \\\n",
        "                P(T) = 0.5                  P(T∩T∩C) = 0.125\n",
        "               /          \\\n",
        "              /            \\                P(T∩C∩T) = 0.125\n",
        "             /              \\              /\n",
        "P(Ω) = 1.0                    P(T∩C) = 0.25            \n",
        "             \\                             \\\n",
        "              \\                             P(T∩C∩C) = 0.125\n",
        "               \\        \n",
        "                \\\n",
        "                 \\\n",
        "                  \\                            P(C∩T∩T) = 0.125\n",
        "                   \\                          /\n",
        "                    \\            P(C∩T) = 0.25\n",
        "                     \\          /             \\\n",
        "                      P(C) = 0.5               P(C∩T∩C) = 0.125\n",
        "                                \\           \n",
        "                                 \\\n",
        "                                  \\               P(C∩C∩T) = 0.125\n",
        "                                   \\             /\n",
        "                                    P(C∩C) = 0.25\n",
        "                                                 \\\n",
        "                                                  P(C∩C∩C) = 0.125\n",
        "```\n",
        "\n",
        "## Esempio 3: Processo di Controllo Qualità\n",
        "\n",
        "Un prodotto passa attraverso tre controlli:\n",
        "1. Controllo materiali (M): 90% passa\n",
        "2. Controllo design (D): 80% passa se i materiali sono ok, 40% altrimenti\n",
        "3. Test finale (T): 95% passa se tutto ok, 60% se fallito un controllo, 30% se falliti entrambi\n",
        "\n",
        "```\n",
        "                                            P(M∩D∩T) = 0.684\n",
        "                                           /\n",
        "                                          /\n",
        "                            P(M∩D) = 0.72\n",
        "                           /              \\\n",
        "                          /                \\\n",
        "                P(M) = 0.9                  P(M∩D∩T') = 0.036\n",
        "               /          \\\n",
        "              /            \\                P(M∩D'∩T) = 0.108\n",
        "             /              \\              /\n",
        "P(Ω) = 1.0                    P(M∩D') = 0.18            \n",
        "             \\                             \\\n",
        "              \\                             P(M∩D'∩T') = 0.072\n",
        "               \\        \n",
        "                \\\n",
        "                 \\\n",
        "                  \\                            P(M'∩D∩T) = 0.024\n",
        "                   \\                          /\n",
        "                    \\            P(M'∩D) = 0.04\n",
        "                     \\          /             \\\n",
        "                      P(M') = 0.1              P(M'∩D∩T') = 0.016\n",
        "                                \\           \n",
        "                                 \\\n",
        "                                  \\               P(M'∩D'∩T) = 0.018\n",
        "                                   \\             /\n",
        "                                    P(M'∩D') = 0.06\n",
        "                                                 \\\n",
        "                                                  P(M'∩D'∩T') = 0.042\n",
        "```\n",
        "\n",
        "Dove:\n",
        "- M' significa \"fallito controllo materiali\"\n",
        "- D' significa \"fallito controllo design\"\n",
        "- T' significa \"fallito test finale\"\n",
        "\n",
        "## Utilizzo degli Alberi delle Probabilità\n",
        "\n",
        "Gli alberi sono particolarmente utili per:\n",
        "\n",
        "1. **Visualizzare sequenze di eventi**\n",
        "   - Mostrare chiaramente come gli eventi si susseguono\n",
        "\n",
        "2. **Calcolare probabilità congiunte**\n",
        "   - Moltiplicare le probabilità lungo i rami (nei casi di sopra non abbiamo scritto le probabilità lungo i rami, ma abbiamo assunto di avere già le probabilità congiunte, che sono le probabilità degli eventi che ogni nodo indica.\n",
        "\n",
        "3. **Trovare probabilità marginali**\n",
        "   - Sommare le probabilità dei rami pertinenti\n",
        "\n",
        "4. **Applicare il teorema di Bayes**! (vedremo cosa sia)\n",
        "   - Visualizzare le relazioni tra probabilità \"a priori\" e condizionate\n",
        "\n",
        "### Suggerimenti per gli esercizi\n",
        "\n",
        "1. **Disegna l'albero completo**\n",
        "   - Non saltare passaggi, anche se sembrano ovvi\n",
        "\n",
        "2. **Scrivi tutte le probabilità**\n",
        "   - Lungo i rami le probabilità condizionate\n",
        "   - Volendo, ai nodi le probabilità congiunte\n",
        "\n",
        "3. **Verifica i totali**\n",
        "   - La somma delle probabilità di tutti i nodi nello stesso livello deve essere sempre 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtiIrwHztfES"
      },
      "source": [
        "# Il Teorema della Probabilità Totale\n",
        "\n",
        "### Concetto di Partizione\n",
        "\n",
        "Una partizione dello spazio campionario $\\Omega$ è un insieme di eventi $\\{\\mathcal{B}_1, \\mathcal{B}_2, ..., \\mathcal{B}_n\\}$ tali che:\n",
        "1. Sono mutuamente esclusivi: $\\mathcal{B}_i \\cap \\mathcal{B}_j = \\emptyset$ per $i \\neq j$\n",
        "2. Sono esaustivi: $\\bigcup_{i=1}^n \\mathcal{B}_i = \\Omega$\n",
        "3. Sono non vuoti: $P(\\mathcal{B}_i) > 0$ per ogni $i$\n",
        "\n",
        "### Teorema\n",
        "\n",
        "Per qualsiasi evento $\\mathcal{A}$ e una partizione $\\{\\mathcal{B}_1, \\mathcal{B}_2, ..., \\mathcal{B}_n\\}$:\n",
        "\n",
        "$$P(\\mathcal{A}) = \\sum_{i=1}^n P(\\mathcal{A}|\\mathcal{B}_i) \\cdot P(\\mathcal{B}_i)$$\n",
        "\n",
        "Questo teorema ci permette di calcolare la probabilità di un evento scomponendola attraverso una partizione dello spazio campionario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk27R9bi0Y5M"
      },
      "source": [
        "# Il Teorema di Bayes e l'inferenza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB3jzRqntwpf"
      },
      "source": [
        "\n",
        "\n",
        "L'inferenza è il processo di trarre conclusioni partendo da premesse o evidenze. Nel contesto probabilistico, spesso vogliamo:\n",
        "1. Capire la causa di un effetto osservato\n",
        "2. Prevedere effetti futuri basandoci su cause note\n",
        "\n",
        "La probabilità condizionata è fondamentale in questo processo perché ci permette di aggiornare le nostre credenze alla luce di nuove informazioni."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z7lDLgJtMgt"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Esempio: Diagnosi Medica\n",
        "- Causa ($\\mathcal{D}$): presenza di una malattia\n",
        "- Effetto ($\\mathcal{S}$): presenza di un sintomo\n",
        "\n",
        "Conosciamo:\n",
        "- $P(\\mathcal{D})$: probabilità a priori della malattia\n",
        "- $P(\\mathcal{S}|\\mathcal{D})$: probabilità del sintomo data la malattia (verosimiglianza)\n",
        "\n",
        "Vogliamo:\n",
        "- $P(\\mathcal{D}|\\mathcal{S})$: probabilità della malattia dato il sintomo (probabilità a posteriori)\n",
        "\n",
        "\n",
        "\n",
        "### Componenti Chiave\n",
        "1. **Probabilità a priori** $P(\\mathcal{H})$: la nostra credenza iniziale su un'ipotesi\n",
        "2. **Verosimiglianza** $P(\\mathcal{E}|\\mathcal{H})$: probabilità dell'evidenza data l'ipotesi\n",
        "3. **Probabilità a posteriori** $P(\\mathcal{H}|\\mathcal{E})$: la credenza aggiornata dopo aver osservato l'evidenza\n",
        "\n",
        "### Formula del teorema di Bayes\n",
        "\n",
        "$$P(\\mathcal{H}|\\mathcal{E}) = \\frac{P(\\mathcal{E}|\\mathcal{H}) \\cdot P(\\mathcal{H})}{P(\\mathcal{E})}$$\n",
        "\n",
        "dove $P(\\mathcal{E})$ può essere calcolato usando il teorema della probabilità totale:\n",
        "\n",
        "$$P(\\mathcal{E}) = P(\\mathcal{E}|\\mathcal{H}) \\cdot P(\\mathcal{H}) + P(\\mathcal{E}|\\neg\\mathcal{H}) \\cdot P(\\neg\\mathcal{H})$$\n",
        "\n",
        "### Interpretazione\n",
        "Il teorema di Bayes ci fornisce un metodo formale per:\n",
        "1. Aggiornare le nostre credenze alla luce di nuove evidenze\n",
        "2. Invertire la direzione della probabilità condizionata (da effetto a causa)\n",
        "3. Combinare informazioni a priori con nuovi dati\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR--7etAt6Mq"
      },
      "source": [
        "\n",
        "### Esempio Numerico\n",
        "Consideriamo un test medico:\n",
        "- $P(\\mathcal{D}) = 0.01$ (1% della popolazione ha la malattia)\n",
        "- $P(\\mathcal{S}|\\mathcal{D}) = 0.95$ (95% di sensibilità del test)\n",
        "- $P(\\mathcal{S}|\\neg\\mathcal{D}) = 0.10$ (10% di falsi positivi)\n",
        "\n",
        "Usando Bayes:\n",
        "\n",
        "$$P(\\mathcal{D}|\\mathcal{S}) = \\frac{0.95 \\cdot 0.01}{0.95 \\cdot 0.01 + 0.10 \\cdot 0.99} \\approx 0.088$$\n",
        "\n",
        "Quindi, anche con un test positivo, la probabilità di avere la malattia è solo circa 8.8%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reYFdjlt2WBY"
      },
      "source": [
        "### Il Teorema di Bayes nell'Era dell'Intelligenza Artificiale Moderna\n",
        "\n",
        "Il teorema di Bayes, formulato più di 250 anni fa, si è rivelato sorprendentemente centrale nello sviluppo dell'intelligenza artificiale moderna. La sua importanza va ben oltre la semplice statistica, permeando sia la nostra comprensione del cervello umano che lo sviluppo di potenti algoritmi di machine learning.\n",
        "\n",
        "Nel campo delle neuroscienze cognitive, l'ipotesi del \"cervello bayesiano\" suggerisce che il nostro cervello funzioni essenzialmente come una macchina di inferenza probabilistica. Secondo questa teoria, percepiamo il mondo non semplicemente raccogliendo informazioni sensoriali, ma piuttosto combinando continuamente le nostre aspettative precedenti (prior) con nuove evidenze (likelihood) per aggiornare la nostra comprensione del mondo (posterior). Questo processo di aggiornamento continuo delle nostre \"credenze\" sul mondo è essenzialmente un'implementazione biologica del teorema di Bayes.\n",
        "\n",
        "Parallelamente, nel campo dell'intelligenza artificiale, l'inferenza bayesiana si è rivelata fondamentale per lo sviluppo di modelli generativi avanzati. Tuttavia, calcolare esattamente le probabilità posteriori in spazi ad alta dimensionalità - come quelli necessari per generare immagini, video o testo - è computazionalmente intrattabile. La svolta è arrivata con lo sviluppo di metodi di approssimazione dell'inferenza bayesiana, in particolare l'inferenza variazionale. Questi metodi permettono di approssimare distribuzioni di probabilità complesse con altre più semplici e trattabili.\n",
        "\n",
        "Questa intuizione ha portato allo sviluppo dei Variational Autoencoders (VAE) e ha influenzato profondamente l'architettura di molti modelli generativi moderni. Anche se modelli come i Diffusion Models o le moderne architetture Transformer non sono esplicitamente bayesiani, incorporano spesso principi di ragionamento probabilistico ispirati all'inferenza bayesiana. Per esempio, il processo di denoising nei modelli di diffusione può essere interpretato come una forma di inferenza bayesiana, dove il modello gradualmente \"raffina\" la sua stima di un'immagine o un video partendo da puro rumore.\n",
        "\n",
        "L'impatto di questo approccio probabilistico si estende alla robustezza dei modelli di AI. Incorporando l'incertezza nei loro predizioni e decisioni, i sistemi di AI moderni possono gestire meglio situazioni ambigue o dati rumorosi. Inoltre, la capacità di quantificare l'incertezza è cruciale in applicazioni critiche come la diagnosi medica o la guida autonoma.\n",
        "\n",
        "Guardando al futuro, mentre continuiamo a sviluppare modelli di AI sempre più sofisticati, i principi dell'inferenza bayesiana rimarranno probabilmente centrali. Non solo come strumento matematico, ma come framework concettuale per pensare all'apprendimento, alla percezione e alla decisione, sia nelle macchine che nel cervello umano. La sfida continua sarà sviluppare metodi sempre più efficienti per approssimare l'inferenza bayesiana in spazi di alta dimensionalità, permettendo ai nostri modelli di ragionare in modo sempre più sofisticato sull'incertezza."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP16dDikyFIu6TrbA26wOGo",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
