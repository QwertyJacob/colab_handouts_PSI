{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QwertyJacob/colab_handouts_PSI/blob/main/3.3.3BONUS_Geometric_Pascal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3N6P0qT-Wl"
      },
      "source": [
        "### 3.3.3 Variabile Aleatoria Geometrica\n",
        "_______________\n",
        "Adattamento da:\n",
        "\n",
        "- Probability for Computer Scientists (CS109 Course Reader), C. Piech, Standford, 2024\n",
        "- Probability and Statistics for Computer Scientists, M. Baron, CRC Press, 2014"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consideriamo nuovamente una sequenza di prove di Bernoulli indipendenti. Ogni prova ha come esito un \"successo\" o un \"insuccesso\". Immagina di essere in un pub con i tuoi amici e di decidere di giocare a freccette. Ogni volta che tiri una freccetta, hai una probabilità $ p $ di colpire il centro (bullseye), e una probabilità $ 1 - p $ di mancarlo.\n",
        "\n",
        "La variabile aleatoria geometrica $ X$ rappresenta il numero di tentativi necessari per ottenere il primo successo (colpire il bullseye).\n",
        "\n",
        "**Esempio:**\n",
        "- Supponiamo che $$ p = 0.2 $$.\n",
        "- Vuoi sapere qual è la probabilità che tu colpisca il bullseye per la prima volta al terzo tentativo.\n",
        "\n",
        "La probabilità che ciò accada è data da:\n",
        "\n",
        "$$ P(X = k) = (1 - p)^{k-1} \\cdot p $$\n",
        "\n",
        "Per $ k = 3 $:\n",
        "\n",
        "$$ P(X = 3) = (1 - 0.2)^{3-1} \\cdot 0.2 = 0.8^2 \\cdot 0.2 = 0.128 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnI_KJhYUcgb",
        "outputId": "7070a2c7-5764-4887-c91e-588c460abe79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La probabilità di colpire il bullseye al terzo tentativo è: 0.128\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def prob_geometrica(p, k):\n",
        "    return (1 - p)**(k - 1) * p\n",
        "\n",
        "p = 0.2\n",
        "k = 3\n",
        "print(f\"La probabilità di colpire il bullseye al terzo tentativo è: {prob_geometrica(p, k):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **DEFINIZIONE 3.12**   Il numero di prove di Bernoulli necessarie per ottenere il primo successo ha **distribuzione geometrica**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Esempio 3.18.** Un motore di ricerca esamina una lista di siti alla ricerca di una determinata frase chiave. Si supponga che la ricerca termini non appena la frase viene trovata. Il numero di siti visitati ha distribuzione geometrica.♦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Esempio 3.19.** Un responsabile delle assunzioni intervista i candidati uno alla volta per coprire un posto vacante. Il numero di candidati intervistati fino a quando uno di essi riceve un'offerta di lavoro ha distribuzione geometrica.\n",
        "\n",
        "♦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Le variabili aleatorie geometriche possono assumere qualsiasi valore intero da 1 a infinito, poiché sono necessarie almeno 1 prova per ottenere il primo successo, e il numero di prove richieste non è limitato superiormente da alcun valore fisso. (Ad esempio, non c'è alcuna garanzia che tra i primi 10 lanci di una moneta ci sia almeno una testa.) L'unico parametro è $ p $, la probabilità di successo.\n",
        "\n",
        "La funzione di massa di probabilità geometrica ha la forma:\n",
        "\n",
        "$$ P(x) = P(\\text{il 1° successo si verifica all'x-esima prova}) = (1 - p)^{x-1} p, \\quad x = 1, 2, \\ldots $$\n",
        "\n",
        "> **Questa rappresenta la probabilità di avere $ x - 1 $ insuccessi seguiti da un successo. Rispetto alla (3.9), in questa formula non compare alcun coefficiente binomiale perché esiste un solo esito in cui il primo successo si verifica esattamente all’$ x $-esima prova.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "È la prima volta che incontriamo una variabile aleatoria illimitata, ovvero senza un limite superiore. La variabile $ X $ può assumere qualsiasi valore intero positivo, da $ 1 $ a $ \\infty $. È utile verificare che $ \\sum_x P(x) = 1 $, come richiesto da ogni funzione di massa di probabilità. Effettivamente:\n",
        "\n",
        "$$\n",
        "\\sum_{x=1}^{\\infty} P(x) = \\sum_{x=1}^{\\infty} (1 - p)^{x-1} p = p \\sum_{k=0}^{\\infty} (1 - p)^k = p \\cdot \\frac{1}{1 - (1 - p)} = p \\cdot \\frac{1}{p} = 1,\n",
        "$$\n",
        "\n",
        "dove si è riconosciuto che la somma a sinistra è una serie geometrica, da cui deriva il nome \"distribuzione geometrica\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Infine, la distribuzione geometrica ha valore atteso $ \\mu = \\frac{1}{p} $ e varianza $ \\sigma^2 = \\frac{1 - p}{p^2} $.\n",
        "\n",
        "**Dimostrazione del valore atteso:** Consideriamo la serie geometrica\n",
        "\n",
        "$$\n",
        "s(q) = \\sum_{x=0}^{\\infty} q^x = \\frac{1}{1 - q}, \\quad \\text{per } |q| < 1.\n",
        "$$\n",
        "\n",
        "Derivando rispetto a $ q $:\n",
        "\n",
        "$$\n",
        "s'(q) = \\left( \\frac{1}{1 - q} \\right)' = \\frac{1}{(1 - q)^2} = \\sum_{x=1}^{\\infty} x q^{x-1}.\n",
        "$$\n",
        "\n",
        "Moltiplicando entrambi i membri per $ p $ e ricordando che $ p = 1 - q $, otteniamo:\n",
        "\n",
        "$$\n",
        "E(X) = \\sum_{x=1}^{\\infty} x (1 - p)^{x-1} p = p \\sum_{x=1}^{\\infty} x q^{x-1} = p \\cdot \\frac{1}{(1 - q)^2} = p \\cdot \\frac{1}{p^2} = \\frac{1}{p}.\n",
        "$$\n",
        "\n",
        "La derivazione della varianza è simile: si calcola la seconda derivata della serie geometrica e, dopo alcuni passaggi, si ottiene un'espressione per $ \\sum x^2 q^{x-1} $, da cui si ricava $ Var(X) $.\n",
        "\n",
        "$$\\square$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dimostrazione Varianza**\n",
        "\n",
        "La varianza si calcola come:\n",
        "$$ Var(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 $$\n",
        "\n",
        "Per trovare $\\mathbb{E}[X^2]$, usiamo la seconda derivata della serie geometrica:\n",
        "$$ \\sum_{k=1}^{\\infty} k^2x^{k-1} = \\frac{1+x}{(1-x)^3} $$\n",
        "\n",
        "Dopo alcuni passaggi algebrici:\n",
        "$$ \\mathbb{E}[X^2] = \\frac{2-p}{p^2} $$\n",
        "\n",
        "Quindi:\n",
        "$$ Var(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\frac{2-p}{p^2} - \\frac{1}{p^2} = \\frac{1-p}{p^2} $$\n",
        "\n",
        "$$\\square$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Sintesi Distribuzione geometrica**  \n",
        "$ p $ = probabilità di successo  \n",
        "$$ P(x) = (1 - p)^{x-1} p, \\quad x = 1, 2, \\ldots $$\n",
        "$$ E(X) = \\frac{1}{p} $$\n",
        "\n",
        "$$ Var(X) = \\frac{1 - p}{p^2} $$\n",
        "$$ \\tag{3.10} $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Esempio 3.20 (Paradosso di San Pietroburgo).**  Questo paradosso fu osservato dal matematico svizzero Daniel Bernoulli (1700–1782), nipote di Jacob. Descrive una strategia di gioco d’azzardo che permetterebbe di vincere una somma di denaro desiderata con probabilità uno. Non sembra una strategia molto attraente? È reale, non c’è alcuna truffa!\n",
        "\n",
        "Consideriamo un gioco che può essere ripetuto un numero arbitrario di volte. I turni sono indipendenti e, ogni volta, la probabilità di vincere è $ p $. Il gioco non deve essere favorevole al giocatore né tantomeno equo: $ p $ può essere qualsiasi probabilità positiva. In ogni turno si scommette una certa somma $ x $. In caso di successo, si vince $ x $. In caso di insuccesso, si perde $ x $.\n",
        "\n",
        "La strategia è semplice: la puntata iniziale è pari all’importo che si desidera vincere. Se si vince un turno, si smette. Se si perde, si raddoppia la puntata e si continua.\n",
        "\n",
        "Supponiamo che il guadagno desiderato sia 100 euro. Il gioco si svolgerà nel modo seguente:\n",
        "\n",
        "| Turno     | 1     | 2     | 3     | ...   |\n",
        "|-----------|-------|-------|-------|-------|\n",
        "| Puntata   | 100   | 200   | 400   | ...   |\n",
        "| Bilancio se si perde | -100  | -300  | -700  | ...   |\n",
        "| Bilancio se si vince | +100 e si ferma | +100 e si ferma | +100 e si ferma | ...   |\n",
        "\n",
        "Prima o poi, si vincerà un turno e, in quel momento, il bilancio sarà +100 euro. Garantito! Tuttavia, non è questo ciò che D. Bernoulli chiamava un paradosso.\n",
        "\n",
        "Quanti turni bisognerà giocare? Poiché ogni turno è una prova di Bernoulli, il numero di turni $ X $ fino al primo successo è una variabile aleatoria geometrica con parametro $ p $.\n",
        "\n",
        "Il gioco è potenzialmente infinito? No. In media, durerà $ E(X) = \\frac{1}{p} $ turni. In un gioco equo con $ p = \\frac{1}{2} $, serviranno in media 2 turni per ottenere la vittoria. In un gioco \"sfavorevole\", con $ p < \\frac{1}{2} $, ci vorrà più tempo, ma comunque un numero finito di turni. Ad esempio, se $ p = 0{,}2 $ (una vittoria ogni cinque turni in media), ci si fermerà dopo $ \\frac{1}{p} = 5 $ turni in media. Ancora, nessun paradosso.\n",
        "\n",
        "Infine, quanto denaro serve per poter seguire questa strategia? Sia $ Y $ l’importo dell’ultima puntata. Secondo la strategia, $ Y = 100 \\cdot 2^{X-1} $. È una variabile aleatoria discreta il cui valore atteso è:\n",
        "\n",
        "$$\n",
        "E(Y) = \\sum_{x=1}^{\\infty} \\left(100 \\cdot 2^{x-1}\\right) P_X(x) = 100 \\sum_{x=1}^{\\infty} 2^{x-1} (1 - p)^{x-1} p = 100p \\sum_{x=1}^{\\infty} \\left(2(1 - p)\\right)^{x-1}\n",
        "$$\n",
        "\n",
        "Questa è una serie geometrica di ragione $ 2(1 - p) $. La somma converge solo se $ 2(1 - p) < 1 $, cioè $ p > \\frac{1}{2} $. Altrimenti diverge. Pertanto:\n",
        "\n",
        "$$\n",
        "E(Y) = \n",
        "\\begin{cases}\n",
        "\\frac{100p}{1 - 2(1 - p)} = \\frac{100p}{2p - 1} & \\text{se } p > \\frac{1}{2}, \\\\\n",
        "+\\infty & \\text{se } p \\leq \\frac{1}{2}.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "**Questo è il Paradosso di San Pietroburgo!** Una variabile aleatoria che assume sempre valori finiti (cioè, il gioco termina quasi certamente) ha un valore atteso infinito. Anche quando il gioco è equo, con $ p = \\frac{1}{2} $, il valore atteso dell’ultima puntata è infinito. Ciò significa che, in media, sarebbe necessario un capitale infinito per applicare questa strategia.\n",
        "\n",
        "Per quanto ne sappiamo, ogni casinò impone un limite massimo alla puntata, impedendo ai giocatori di applicare completamente la strategia di San Pietroburgo. Quando un tale limite è presente, si può dimostrare che non esiste una strategia vincente.\n",
        "\n",
        "♦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.4 **Variabile Aleatoria di Pascal (o Binomiale Negativa)**\n",
        "Quando abbiamo studiato la distribuzione geometrica e il paradosso di San Pietroburgo nella Sezione 3.3.3, giocavamo fino al primo successo. Ora, invece, continuiamo a giocare fino a ottenere $ k $ successi. Il numero di partite giocate in questo caso ha distribuzione binomiale negativa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "> **DEFINIZIONE 3.13**  In una sequenza di prove di Bernoulli indipendenti, il numero di prove necessarie per ottenere $ k $ successi ha **distribuzione binomiale negativa**.\n",
        "\n",
        "In un certo senso, la distribuzione binomiale negativa è l'opposta della distribuzione binomiale: le variabili binomiali contano il numero di successi in un numero fissato di prove, mentre le variabili binomiali negative contano il numero di prove necessarie per osservare un numero fissato di successi. A parte questa differenza, non c'è nulla di \"negativo\" in questa distribuzione.\n",
        "\n",
        "La funzione di massa di probabilità binomiale negativa è:\n",
        "\n",
        "$$\n",
        "P(x) = P(\\text{l'x-esima prova produce il k-esimo successo})\n",
        "$$\n",
        "\n",
        "$$\n",
        "= P\\left\\{ \\begin{array}{c}\n",
        "(k - 1) \\text{ successi nelle prime } (x - 1) \\text{ prove,} \\\\\n",
        "\\text{e l'ultima prova è un successo}\n",
        "\\end{array} \\right\\}\n",
        "= \\binom{x-1}{k-1} (1 - p)^{x-k} p^k.\n",
        "$$\n",
        "\n",
        "Questa formula tiene conto della probabilità di $ k $ successi, delle $ x - k $ prove con insuccesso, e del numero di sequenze (esiti) in cui il $ k $-esimo successo si verifica esattamente all’$ x $-esima prova.\n",
        "\n",
        "La distribuzione binomiale negativa ha due parametri: $ k $ e $ p $. Nel caso $ k = 1 $, si riduce alla distribuzione geometrica. Inoltre, ogni variabile aleatoria con distribuzione binomiale negativa può essere rappresentata come somma di $ k $ variabili aleatorie geometriche indipendenti,\n",
        "\n",
        "$$\n",
        "X = X_1 + \\ldots + X_k, \\tag{3.11}\n",
        "$$\n",
        "\n",
        "\n",
        "tutte con la stessa probabilità di successo $ p $. Infatti, il numero di prove fino al $ k $-esimo successo è dato da un numero geometrico di prove $ X_1 $ fino al primo successo, più un ulteriore numero geometrico di prove $ X_2 $ fino al secondo successo, e così via.\n",
        "\n",
        "Grazie alla rappresentazione (3.11), otteniamo:\n",
        "\n",
        "$$\n",
        "E(X) = E(X_1 + \\ldots + X_k) = \\frac{1}{p} + \\ldots + \\frac{1}{p} = \\frac{k}{p}\n",
        "$$\n",
        "\n",
        "e\n",
        "\n",
        "$$\n",
        "Var(X) = Var(X_1 + \\ldots + X_k) = \\frac{1 - p}{p^2} + \\ldots + \\frac{1 - p}{p^2} = \\frac{k(1 - p)}{p^2}.\n",
        "$$\n",
        "\n",
        "**Sintesi Distribuzione binomiale negativa**  \n",
        "$ k $ = numero di successi  \n",
        "$ p $ = probabilità di successo  \n",
        "$$ P(x) = \\binom{x-1}{k-1} (1 - p)^{x-k} p^k, \\quad x = k, k + 1, \\ldots $$\n",
        "$$ E(X) = \\frac{k}{p} $$\n",
        "$$ Var(X) = \\frac{k(1 - p)}{p^2} $$\n",
        "$$ \\tag{3.12} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5rfcS6XUflW"
      },
      "source": [
        "> **Esempio(BONUS):** vuoi sapere quanti tentativi ti servono per colpire il bullseye esattamente 2 volte ($ r = 2 $).\n",
        "\n",
        "La probabilità che tu ottenga il secondo successo al $ k $-esimo tentativo è:\n",
        "$ P(Y = k) = \\binom{k-1}{r-1} \\cdot p^r \\cdot (1-p)^{k-r} $\n",
        "\n",
        "Per $ r = 2 $ e $ k = 5 $:\n",
        "\n",
        "$$ P(Y = 5) = \\binom{4}{1} \\cdot 0.2^2 \\cdot 0.8^3 = 4 \\cdot 0.04 \\cdot 0.512 = 0.08192 $$\n",
        "\n",
        "**Codice Python per calcolare questa probabilità:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJH-UZqDUxzZ",
        "outputId": "82afefef-98ac-409c-a8c3-05ec0d13d471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La probabilità di colpire il bullseye 2 volte entro il quinto tentativo è: 0.08192\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def prob_pascal(r, p, k):\n",
        "    return math.comb(k-1, r-1) * (p**r) * ((1-p)**(k-r))\n",
        "\n",
        "r, p, k = 2, 0.2, 5\n",
        "print(f\"La probabilità di colpire il bullseye 2 volte entro il quinto tentativo è: {prob_pascal(r, p, k):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTU1x0E2T8p2"
      },
      "source": [
        "**Ricorda:**\n",
        "\n",
        "- **Geometrica:** Questa distribuzione è utile quando si vuole sapere quanti temtativi ci vogliono per ottenere il primo successo in una serie di tentativi indipendenti.\n",
        "- **Pascal:** Questa estende il concetto, utile per sapere quanti tentativi ci vogliono per ottenere un numero fisso di successi, il che è molto utile in situazioni dove non ti basta un solo successo, ma ne servono diversi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A7ms-6gVE28"
      },
      "source": [
        "> **Esempio (BONUS)** Un gruppo di amici decide di giocare a un gioco di dadi, e vogliono calcolare le probabilità di ottenere un certo risultato. \n",
        "\n",
        "Iniziamo con la variabile aleatoria geometrica. Supponiamo che uno dei nostri amici, Marco, voglia sapere quante volte deve lanciare un dado per ottenere un **6**. Ogni lancio del dado è un esperimento indipendente, e la probabilità di ottenere un **6** è $ p = \\frac{1}{6} $.\n",
        "\n",
        "La variabile aleatoria geometrica $ X $ rappresenta il numero di lanci necessari fino al primo successo (ovvero, fino a quando Marco ottiene un **6**).\n",
        "\n",
        "La funzione di probabilità della variabile aleatoria geometrica è data da:\n",
        "\n",
        "$$\n",
        "P(X = k) = (1 - p)^{k-1} \\cdot p\n",
        "$$\n",
        "\n",
        "dove:\n",
        "- $ k $ è il numero di lanci necessari,\n",
        "- $ p $ è la probabilità di successo in un singolo lancio.\n",
        "\n",
        "Vediamo come calcolare la probabilità che Marco ottenga un **6** al quarto lancio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmp4_bkvVd2j",
        "outputId": "9635d61f-e258-4631-8419-5529698aae7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La probabilità di ottenere un 6 al quarto lancio è: 0.0965\n"
          ]
        }
      ],
      "source": [
        "def probabilita_geometrica(k, p):\n",
        "    q = 1 - p  # probabilità di insuccesso\n",
        "    return (q ** (k - 1)) * p\n",
        "\n",
        "# Parametri\n",
        "k = 4  # numero di lanci\n",
        "p = 1/6  # probabilità di ottenere un 6\n",
        "\n",
        "# Calcolo della probabilità\n",
        "probabilita = probabilita_geometrica(k, p)\n",
        "print(f\"La probabilità di ottenere un 6 al quarto lancio è: {probabilita:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Esempio 3.21 (Test sequenziale).** In un recente lotto di produzione, il 5% di certi componenti elettronici è difettoso. Dobbiamo trovare 12 componenti non difettosi per i nostri 12 nuovi computer. I componenti vengono testati fino a quando non si individuano 12 elementi non difettosi. Qual è la probabilità che debbano essere testati più di 15 componenti?\n",
        "\n",
        "**Soluzione.** Sia $ X $ il numero di componenti testati fino a trovare 12 non difettosi. Si tratta del numero di prove necessarie per ottenere 12 successi, quindi $ X $ ha distribuzione binomiale negativa con $ k = 12 $ e $ p = 0{,}95 $ (poiché la probabilità che un componente sia non difettoso è $ 1 - 0{,}05 = 0{,}95 $).\n",
        "\n",
        "Dobbiamo calcolare $ P(X > 15) = \\sum_{x=16}^{\\infty} P(x)$; Come possiamo procedere in modo più rapido?\n",
        "\n",
        "Virtuosamente, ogni problema relativo alla distribuzione binomiale negativa può essere risolto utilizzando la distribuzione binomiale. Sebbene $ X $ non sia affatto una variabile binomiale, la probabilità $ P(X > 15) $ può essere espressa in termini di una variabile aleatoria binomiale. Nel nostro caso:\n",
        "\n",
        "$$\n",
        "P(X > 15) = P(\\text{più di 15 prove necessarie per ottenere 12 successi})\n",
        "$$\n",
        "\n",
        "$$\n",
        "= P(\\text{15 prove non sono sufficienti}) = P(\\text{meno di 12 successi nelle prime 15 prove})\n",
        "$$\n",
        "\n",
        "$$\n",
        "= P(Y < 12),\n",
        "$$\n",
        "\n",
        "dove $ Y $ è il numero di successi (componenti non difettosi) in 15 prove, ovvero una variabile aleatoria binomiale con parametri $ n = 15 $ e $ p = 0{,}95 $. \n",
        "\n",
        "$$\n",
        "P(X > 15) = P(Y < 12) = P(Y \\leq 11) = 0{,}0055.\n",
        "$$\n",
        "\n",
        "Questa tecnica, che consiste nell’esprimere una probabilità relativa a una variabile aleatoria in termini di un’altra variabile aleatoria, è molto utile. \n",
        "\n",
        "♦\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqXggzZJVDYV"
      },
      "source": [
        "- **Approfondimento**: https://dariomalchiodi.gitlab.io/sad-python-book/L11-Distribuzione_geometrica.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMc2sM7Y7rPCEsK448ym6oA",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
